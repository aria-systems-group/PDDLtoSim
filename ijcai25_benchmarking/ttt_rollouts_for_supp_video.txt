****************************** F(win) **************************************************
****************************** Robot -1st **********************************************
This rollout shows both strategy and overly optimistic moves. The robot in 3 step play strategically. Then, in the 5th move is optimistic.



root@668db2aaa591:~/pddltosim# /usr/bin/python3 /root/pddltosim/main.py
pybullet build time: Nov 28 2023 23:45:17
No. of nodes in the Two player game is :5478
No. of edges in the Two player game is :16167
Done building the Product Automaton
No. of nodes in the DFA game is :5479
No. of edges in the DFA game is :16790
Computing Cooperative Winning strategy
/root/pddltosim/regret_synthesis_toolbox/src/strategy_synthesis/value_iteration.py:429: RuntimeWarning: invalid value encountered in cast
  _int_val_vector = self.val_vector[:, -1].astype(int)
******************** Co-op Computation time: 5.764467477798462 ********************
Computing Winning strategy
/root/pddltosim/regret_synthesis_toolbox/src/strategy_synthesis/value_iteration.py:681: RuntimeWarning: invalid value encountered in cast
  _int_val_vector = self.val_vector[:, -1].astype(int)
******************** WCo-op Computation time: 5.284619331359863 ********************
Computing Safety strategy
Checking Safe-Adm strategy exists
******************** Safe-Admissible Computation time: 0.07968473434448242 ********************
Computing Hopeful strategy
******************** Hope-Admissible Computation time: 5.526450157165527 ********************
Function compute_strategy took 16.665754318237305 seconds to run.
There does not exist a winning strategy!
[0], state:((1, 0, 0, 0, 0, 0, 0, 0, 0), 'q1'): Pen, action: robot_place_0_0: 3
[1], state:((0, 1, 0, 0, 0, 0, 0, 0, 0), 'q1'): Pen, action: robot_place_0_1: 3
[2], state:((0, 0, 1, 0, 0, 0, 0, 0, 0), 'q1'): Pen, action: robot_place_0_2: 3
[3], state:((0, 0, 0, 1, 0, 0, 0, 0, 0), 'q1'): Pen, action: robot_place_1_0: 3
[4], state:((0, 0, 0, 0, 1, 0, 0, 0, 0), 'q1'): Pen, action: robot_place_1_1: 3
[5], state:((0, 0, 0, 0, 0, 1, 0, 0, 0), 'q1'): Pen, action: robot_place_1_2: 3
[6], state:((0, 0, 0, 0, 0, 0, 1, 0, 0), 'q1'): Pen, action: robot_place_2_0: 3
[7], state:((0, 0, 0, 0, 0, 0, 0, 1, 0), 'q1'): Pen, action: robot_place_2_1: 3
[8], state:((0, 0, 0, 0, 0, 0, 0, 0, 1), 'q1'): Pen, action: robot_place_2_2: 3
Sys Strategy: [Hope-Adm][Coop Opt] ((1, 0, 0, 0, 0, 0, 0, 0, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((0, 1, 0, 0, 0, 0, 0, 0, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((0, 0, 1, 0, 0, 0, 0, 0, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((0, 0, 0, 1, 0, 0, 0, 0, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((0, 0, 0, 0, 1, 0, 0, 0, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((0, 0, 0, 0, 0, 1, 0, 0, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((0, 0, 0, 0, 0, 0, 1, 0, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((0, 0, 0, 0, 0, 0, 0, 1, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((0, 0, 0, 0, 0, 0, 0, 0, 1), 'q1')
Enter state to select from: 0
Choosing state: ((1, 0, 0, 0, 0, 0, 0, 0, 0), 'q1')
R | - | -
- | - | -
- | - | -
[0], state:((1, 2, 0, 0, 0, 0, 0, 0, 0), 'q1'): Pen, action: human_place_0_1: 3
[1], state:((1, 0, 2, 0, 0, 0, 0, 0, 0), 'q1'): Pen, action: human_place_0_2: 3
[2], state:((1, 0, 0, 2, 0, 0, 0, 0, 0), 'q1'): Pen, action: human_place_1_0: 3
[3], state:((1, 0, 0, 0, 2, 0, 0, 0, 0), 'q1'): Pen, action: human_place_1_1: 3
[4], state:((1, 0, 0, 0, 0, 2, 0, 0, 0), 'q1'): Pen, action: human_place_1_2: 3
[5], state:((1, 0, 0, 0, 0, 0, 2, 0, 0), 'q1'): Pen, action: human_place_2_0: 3
[6], state:((1, 0, 0, 0, 0, 0, 0, 2, 0), 'q1'): Pen, action: human_place_2_1: 3
[7], state:((1, 0, 0, 0, 0, 0, 0, 0, 2), 'q1'): Pen, action: human_place_2_2: 3
Enter state to select from: 3
Choosing state: ((1, 0, 0, 0, 2, 0, 0, 0, 0), 'q1')
R | - | -
- | H | -
- | - | -
human_place_1_1
[0], state:((1, 1, 0, 0, 2, 0, 0, 0, 0), 'q1'): Pen, action: robot_place_0_1: 2
[1], state:((1, 0, 1, 0, 2, 0, 0, 0, 0), 'q1'): Pen, action: robot_place_0_2: 3
[2], state:((1, 0, 0, 1, 2, 0, 0, 0, 0), 'q1'): Pen, action: robot_place_1_0: 2
[3], state:((1, 0, 0, 0, 2, 1, 0, 0, 0), 'q1'): Pen, action: robot_place_1_2: 3
[4], state:((1, 0, 0, 0, 2, 0, 1, 0, 0), 'q1'): Pen, action: robot_place_2_0: 3
[5], state:((1, 0, 0, 0, 2, 0, 0, 1, 0), 'q1'): Pen, action: robot_place_2_1: 3
[6], state:((1, 0, 0, 0, 2, 0, 0, 0, 1), 'q1'): Pen, action: robot_place_2_2: 2
Sys Strategy: [Hope-Adm][Coop Opt] ((1, 1, 0, 0, 2, 0, 0, 0, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((1, 0, 0, 1, 2, 0, 0, 0, 0), 'q1')
Sys Strategy: [Hope-Adm] ((1, 0, 0, 0, 2, 0, 0, 0, 1), 'q1')
Enter state to select from: 6
Choosing state: ((1, 0, 0, 0, 2, 0, 0, 0, 1), 'q1')
R | - | -
- | H | -
- | - | R
robot_place_2_2
[0], state:((1, 2, 0, 0, 2, 0, 0, 0, 1), 'q1'): Pen, action: human_place_0_1: 2
[1], state:((1, 0, 2, 0, 2, 0, 0, 0, 1), 'q1'): Pen, action: human_place_0_2: 2
[2], state:((1, 0, 0, 2, 2, 0, 0, 0, 1), 'q1'): Pen, action: human_place_1_0: 2
[3], state:((1, 0, 0, 0, 2, 2, 0, 0, 1), 'q1'): Pen, action: human_place_1_2: 2
[4], state:((1, 0, 0, 0, 2, 0, 2, 0, 1), 'q1'): Pen, action: human_place_2_0: 2
[5], state:((1, 0, 0, 0, 2, 0, 0, 2, 1), 'q1'): Pen, action: human_place_2_1: 2
Enter state to select from: 0
Choosing state: ((1, 2, 0, 0, 2, 0, 0, 0, 1), 'q1')
R | H | -
- | H | -
- | - | R
human_place_0_1
[0], state:((1, 2, 1, 0, 2, 0, 0, 0, 1), 'q1'): Pen, action: robot_place_0_2: inf
[1], state:((1, 2, 0, 1, 2, 0, 0, 0, 1), 'q1'): Pen, action: robot_place_1_0: inf
[2], state:((1, 2, 0, 0, 2, 1, 0, 0, 1), 'q1'): Pen, action: robot_place_1_2: 2
[3], state:((1, 2, 0, 0, 2, 0, 1, 0, 1), 'q1'): Pen, action: robot_place_2_0: 1
[4], state:((1, 2, 0, 0, 2, 0, 0, 1, 1), 'q1'): Pen, action: robot_place_2_1: 2
Sys Strategy: [Hope-Adm][Coop Opt] ((1, 2, 0, 0, 2, 0, 1, 0, 1), 'q1')
Enter state to select from: 3
Choosing state: ((1, 2, 0, 0, 2, 0, 1, 0, 1), 'q1')
R | H | -
- | H | -
R | - | R
robot_place_2_0
[0], state:((1, 2, 2, 0, 2, 0, 1, 0, 1), 'q1'): Pen, action: human_place_0_2: 1
[1], state:((1, 2, 0, 2, 2, 0, 1, 0, 1), 'q1'): Pen, action: human_place_1_0: 1
[2], state:((1, 2, 0, 0, 2, 2, 1, 0, 1), 'q1'): Pen, action: human_place_1_2: 1

**************************Rollout for Video ******************************
R | - | -
- | - | -
- | - | -

R | - | -
- | H | -
- | - | -

R | - | -
- | H | -
- | - | R


R | H | -
- | H | -
- | - | R

R | H | -
- | H | -
R | - | R

Action Seq:
robot_place_0_0
human_place_1_1
robot_place_2_2
human_place_0_1
robot_place_2_0
human_place_2_1


****************************** F(win) **************************************************
****************************** Human -1st **********************************************
This rollout shows Sys is playing overly optimistic moves. The Sys is picking moves indifferently as all state values are infinity even when the Env player is not playing hopelessly.
This means, the only way Sys can win the game is when Env makes a mistake.


root@668db2aaa591:~/pddltosim# /usr/bin/python3 /root/pddltosim/main.py
pybullet build time: Nov 28 2023 23:45:17
No. of nodes in the Two player game is :5478
No. of edges in the Two player game is :16167
Done building the Product Automaton
No. of nodes in the DFA game is :5479
No. of edges in the DFA game is :17038
Computing Cooperative Winning strategy
/root/pddltosim/regret_synthesis_toolbox/src/strategy_synthesis/value_iteration.py:429: RuntimeWarning: invalid value encountered in cast
  _int_val_vector = self.val_vector[:, -1].astype(int)
******************** Co-op Computation time: 5.92777156829834 ********************
Computing Winning strategy
/root/pddltosim/regret_synthesis_toolbox/src/strategy_synthesis/value_iteration.py:681: RuntimeWarning: invalid value encountered in cast
  _int_val_vector = self.val_vector[:, -1].astype(int)
******************** WCo-op Computation time: 5.277949333190918 ********************
Computing Safety strategy
Checking Safe-Adm strategy exists
******************** Safe-Admissible Computation time: 0.07502460479736328 ********************
Computing Hopeful strategy
******************** Hope-Admissible Computation time: 5.3254923820495605 ********************
Function compute_strategy took 16.615944385528564 seconds to run.
There does not exist a winning strategy!
[0], state:((2, 0, 0, 0, 0, 0, 0, 0, 0), 'q1'): Pen, action: human_place_0_0: 4
[1], state:((0, 2, 0, 0, 0, 0, 0, 0, 0), 'q1'): Pen, action: human_place_0_1: 4
[2], state:((0, 0, 2, 0, 0, 0, 0, 0, 0), 'q1'): Pen, action: human_place_0_2: 4
[3], state:((0, 0, 0, 2, 0, 0, 0, 0, 0), 'q1'): Pen, action: human_place_1_0: 4
[4], state:((0, 0, 0, 0, 2, 0, 0, 0, 0), 'q1'): Pen, action: human_place_1_1: inf
[5], state:((0, 0, 0, 0, 0, 2, 0, 0, 0), 'q1'): Pen, action: human_place_1_2: 4
[6], state:((0, 0, 0, 0, 0, 0, 2, 0, 0), 'q1'): Pen, action: human_place_2_0: 4
[7], state:((0, 0, 0, 0, 0, 0, 0, 2, 0), 'q1'): Pen, action: human_place_2_1: 4
[8], state:((0, 0, 0, 0, 0, 0, 0, 0, 2), 'q1'): Pen, action: human_place_2_2: 4
Enter state to select from: 4
Choosing state: ((0, 0, 0, 0, 2, 0, 0, 0, 0), 'q1')
- | - | -
- | H | -
- | - | -
[0], state:((1, 0, 0, 0, 2, 0, 0, 0, 0), 'q1'): Pen, action: robot_place_0_0: inf
[1], state:((0, 1, 0, 0, 2, 0, 0, 0, 0), 'q1'): Pen, action: robot_place_0_1: inf
[2], state:((0, 0, 1, 0, 2, 0, 0, 0, 0), 'q1'): Pen, action: robot_place_0_2: inf
[3], state:((0, 0, 0, 1, 2, 0, 0, 0, 0), 'q1'): Pen, action: robot_place_1_0: inf
[4], state:((0, 0, 0, 0, 2, 1, 0, 0, 0), 'q1'): Pen, action: robot_place_1_2: inf
[5], state:((0, 0, 0, 0, 2, 0, 1, 0, 0), 'q1'): Pen, action: robot_place_2_0: inf
[6], state:((0, 0, 0, 0, 2, 0, 0, 1, 0), 'q1'): Pen, action: robot_place_2_1: inf
[7], state:((0, 0, 0, 0, 2, 0, 0, 0, 1), 'q1'): Pen, action: robot_place_2_2: inf
Sys Strategy: [Hope-Adm][Coop Opt] ((1, 0, 0, 0, 2, 0, 0, 0, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((0, 1, 0, 0, 2, 0, 0, 0, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((0, 0, 1, 0, 2, 0, 0, 0, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((0, 0, 0, 1, 2, 0, 0, 0, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((0, 0, 0, 0, 2, 1, 0, 0, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((0, 0, 0, 0, 2, 0, 1, 0, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((0, 0, 0, 0, 2, 0, 0, 1, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((0, 0, 0, 0, 2, 0, 0, 0, 1), 'q1')
Enter state to select from: 1
Choosing state: ((0, 1, 0, 0, 2, 0, 0, 0, 0), 'q1')
- | R | -
- | H | -
- | - | -
robot_place_0_1
[0], state:((2, 1, 0, 0, 2, 0, 0, 0, 0), 'q1'): Pen, action: human_place_0_0: inf
[1], state:((0, 1, 2, 0, 2, 0, 0, 0, 0), 'q1'): Pen, action: human_place_0_2: inf
[2], state:((0, 1, 0, 2, 2, 0, 0, 0, 0), 'q1'): Pen, action: human_place_1_0: inf
[3], state:((0, 1, 0, 0, 2, 2, 0, 0, 0), 'q1'): Pen, action: human_place_1_2: inf
[4], state:((0, 1, 0, 0, 2, 0, 2, 0, 0), 'q1'): Pen, action: human_place_2_0: 2
[5], state:((0, 1, 0, 0, 2, 0, 0, 2, 0), 'q1'): Pen, action: human_place_2_1: 3
[6], state:((0, 1, 0, 0, 2, 0, 0, 0, 2), 'q1'): Pen, action: human_place_2_2: 2
Enter state to select from: 0
Choosing state: ((2, 1, 0, 0, 2, 0, 0, 0, 0), 'q1')
H | R | -
- | H | -
- | - | -
human_place_0_0
[0], state:((2, 1, 1, 0, 2, 0, 0, 0, 0), 'q1'): Pen, action: robot_place_0_2: inf
[1], state:((2, 1, 0, 0, 2, 1, 0, 0, 0), 'q1'): Pen, action: robot_place_1_2: inf
[2], state:((2, 1, 0, 0, 2, 0, 1, 0, 0), 'q1'): Pen, action: robot_place_2_0: inf
[3], state:((2, 1, 0, 0, 2, 0, 0, 1, 0), 'q1'): Pen, action: robot_place_2_1: inf
[4], state:((2, 1, 0, 0, 2, 0, 0, 0, 1), 'q1'): Pen, action: robot_place_2_2: inf
Sys Strategy: [Hope-Adm][Coop Opt] ((2, 1, 1, 0, 2, 0, 0, 0, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((2, 1, 0, 0, 2, 1, 0, 0, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((2, 1, 0, 0, 2, 0, 1, 0, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((2, 1, 0, 0, 2, 0, 0, 1, 0), 'q1')
Sys Strategy: [Hope-Adm][Coop Opt] ((2, 1, 0, 0, 2, 0, 0, 0, 1), 'q1')
Enter state to select from: 


**************************Rollout for Video ******************************

Action Seq:
human_place_1_1
robot_place_0_1
human_place_0_0
robot_place_2_1
human_place_2_2

- | - | -
- | H | -
- | - | -

- | R | -
- | H | -
- | - | -

H | R | -
- | H | -
- | - | -


H | R | -
- | H | -
- | R | -


H | R | -
- | H | -
- | R | H

****************************** F(win | draw) **************************************************
****************************** Robot -1st **********************************************
Sys ensures draw and is playing WCoop stratgies. Thus, under this strtegy it is playing moves that does not allow more room for human to make an error.





root@668db2aaa591:~/pddltosim# /usr/bin/python3 /root/pddltosim/main.py
pybullet build time: Nov 28 2023 23:45:17
No. of nodes in the Two player game is :5478
No. of edges in the Two player game is :16167
Done building the Product Automaton
No. of nodes in the DFA game is :5479
No. of edges in the DFA game is :16790
Computing Cooperative Winning strategy
/root/pddltosim/regret_synthesis_toolbox/src/strategy_synthesis/value_iteration.py:429: RuntimeWarning: invalid value encountered in cast
  _int_val_vector = self.val_vector[:, -1].astype(int)
******************** Co-op Computation time: 6.111075162887573 ********************
Computing Winning strategy
/root/pddltosim/regret_synthesis_toolbox/src/strategy_synthesis/value_iteration.py:681: RuntimeWarning: invalid value encountered in cast
  _int_val_vector = self.val_vector[:, -1].astype(int)
******************** WCo-op Computation time: 5.798256158828735 ********************
Function compute_strategy took 11.918048858642578 seconds to run.
[0], state:((1, 0, 0, 0, 0, 0, 0, 0, 0), 'q1'): Win, action: robot_place_0_0: 4
[1], state:((0, 1, 0, 0, 0, 0, 0, 0, 0), 'q1'): Win, action: robot_place_0_1: 4
[2], state:((0, 0, 1, 0, 0, 0, 0, 0, 0), 'q1'): Win, action: robot_place_0_2: 4
[3], state:((0, 0, 0, 1, 0, 0, 0, 0, 0), 'q1'): Win, action: robot_place_1_0: 4
[4], state:((0, 0, 0, 0, 1, 0, 0, 0, 0), 'q1'): Win, action: robot_place_1_1: 4
[5], state:((0, 0, 0, 0, 0, 1, 0, 0, 0), 'q1'): Win, action: robot_place_1_2: 4
[6], state:((0, 0, 0, 0, 0, 0, 1, 0, 0), 'q1'): Win, action: robot_place_2_0: 4
[7], state:((0, 0, 0, 0, 0, 0, 0, 1, 0), 'q1'): Win, action: robot_place_2_1: 4
[8], state:((0, 0, 0, 0, 0, 0, 0, 0, 1), 'q1'): Win, action: robot_place_2_2: 4
Sys Strategy: [Wcoop] ((1, 0, 0, 0, 0, 0, 0, 0, 0), 'q1')
Sys Strategy: [Wcoop] ((0, 1, 0, 0, 0, 0, 0, 0, 0), 'q1')
Sys Strategy: [Wcoop] ((0, 0, 1, 0, 0, 0, 0, 0, 0), 'q1')
Sys Strategy: [Wcoop] ((0, 0, 0, 1, 0, 0, 0, 0, 0), 'q1')
Sys Strategy: [Wcoop] ((0, 0, 0, 0, 1, 0, 0, 0, 0), 'q1')
Sys Strategy: [Wcoop] ((0, 0, 0, 0, 0, 1, 0, 0, 0), 'q1')
Sys Strategy: [Wcoop] ((0, 0, 0, 0, 0, 0, 1, 0, 0), 'q1')
Sys Strategy: [Wcoop] ((0, 0, 0, 0, 0, 0, 0, 1, 0), 'q1')
Sys Strategy: [Wcoop] ((0, 0, 0, 0, 0, 0, 0, 0, 1), 'q1')
Enter state to select from: 0
Choosing state: ((1, 0, 0, 0, 0, 0, 0, 0, 0), 'q1')
R | - | -
- | - | -
- | - | -
[0], state:((1, 2, 0, 0, 0, 0, 0, 0, 0), 'q1'): Win, action: human_place_0_1: 3
[1], state:((1, 0, 2, 0, 0, 0, 0, 0, 0), 'q1'): Win, action: human_place_0_2: 3
[2], state:((1, 0, 0, 2, 0, 0, 0, 0, 0), 'q1'): Win, action: human_place_1_0: 3
[3], state:((1, 0, 0, 0, 2, 0, 0, 0, 0), 'q1'): Win, action: human_place_1_1: 4
[4], state:((1, 0, 0, 0, 0, 2, 0, 0, 0), 'q1'): Win, action: human_place_1_2: 3
[5], state:((1, 0, 0, 0, 0, 0, 2, 0, 0), 'q1'): Win, action: human_place_2_0: 3
[6], state:((1, 0, 0, 0, 0, 0, 0, 2, 0), 'q1'): Win, action: human_place_2_1: 3
[7], state:((1, 0, 0, 0, 0, 0, 0, 0, 2), 'q1'): Win, action: human_place_2_2: 3
Enter state to select from: 3
Choosing state: ((1, 0, 0, 0, 2, 0, 0, 0, 0), 'q1')
R | - | -
- | H | -
- | - | -
human_place_1_1
[0], state:((1, 1, 0, 0, 2, 0, 0, 0, 0), 'q1'): Win, action: robot_place_0_1: 3
[1], state:((1, 0, 1, 0, 2, 0, 0, 0, 0), 'q1'): Win, action: robot_place_0_2: 3
[2], state:((1, 0, 0, 1, 2, 0, 0, 0, 0), 'q1'): Win, action: robot_place_1_0: 3
[3], state:((1, 0, 0, 0, 2, 1, 0, 0, 0), 'q1'): Win, action: robot_place_1_2: 3
[4], state:((1, 0, 0, 0, 2, 0, 1, 0, 0), 'q1'): Win, action: robot_place_2_0: 3
[5], state:((1, 0, 0, 0, 2, 0, 0, 1, 0), 'q1'): Win, action: robot_place_2_1: 3
[6], state:((1, 0, 0, 0, 2, 0, 0, 0, 1), 'q1'): Win, action: robot_place_2_2: 3
Sys Strategy: [Wcoop] ((1, 1, 0, 0, 2, 0, 0, 0, 0), 'q1')
Sys Strategy: [Wcoop] ((1, 0, 1, 0, 2, 0, 0, 0, 0), 'q1')
Sys Strategy: [Wcoop] ((1, 0, 0, 1, 2, 0, 0, 0, 0), 'q1')
Sys Strategy: [Wcoop] ((1, 0, 0, 0, 2, 0, 1, 0, 0), 'q1')
Enter state to select from: 0
Choosing state: ((1, 1, 0, 0, 2, 0, 0, 0, 0), 'q1')
R | R | -
- | H | -
- | - | -
robot_place_0_1
[0], state:((1, 1, 2, 0, 2, 0, 0, 0, 0), 'q1'): Win, action: human_place_0_2: 3
[1], state:((1, 1, 0, 2, 2, 0, 0, 0, 0), 'q1'): Win, action: human_place_1_0: 1
[2], state:((1, 1, 0, 0, 2, 2, 0, 0, 0), 'q1'): Win, action: human_place_1_2: 1
[3], state:((1, 1, 0, 0, 2, 0, 2, 0, 0), 'q1'): Win, action: human_place_2_0: 1
[4], state:((1, 1, 0, 0, 2, 0, 0, 2, 0), 'q1'): Win, action: human_place_2_1: 1
[5], state:((1, 1, 0, 0, 2, 0, 0, 0, 2), 'q1'): Win, action: human_place_2_2: 1
Enter state to select from: 0
Choosing state: ((1, 1, 2, 0, 2, 0, 0, 0, 0), 'q1')
R | R | H
- | H | -
- | - | -
human_place_0_2
[0], state:((1, 1, 2, 1, 2, 0, 0, 0, 0), 'q1'): Win, action: robot_place_1_0: inf
[1], state:((1, 1, 2, 0, 2, 1, 0, 0, 0), 'q1'): Win, action: robot_place_1_2: inf
[2], state:((1, 1, 2, 0, 2, 0, 1, 0, 0), 'q1'): Win, action: robot_place_2_0: 2
[3], state:((1, 1, 2, 0, 2, 0, 0, 1, 0), 'q1'): Win, action: robot_place_2_1: inf
[4], state:((1, 1, 2, 0, 2, 0, 0, 0, 1), 'q1'): Win, action: robot_place_2_2: inf
Sys Strategy: [Wcoop] ((1, 1, 2, 0, 2, 0, 1, 0, 0), 'q1')
Enter state to select from: 2
Choosing state: ((1, 1, 2, 0, 2, 0, 1, 0, 0), 'q1')
R | R | H
- | H | -
R | - | -
robot_place_2_0
[0], state:((1, 1, 2, 2, 2, 0, 1, 0, 0), 'q1'): Win, action: human_place_1_0: 2
[1], state:((1, 1, 2, 0, 2, 2, 1, 0, 0), 'q1'): Win, action: human_place_1_2: 1
[2], state:((1, 1, 2, 0, 2, 0, 1, 2, 0), 'q1'): Win, action: human_place_2_1: 1
[3], state:((1, 1, 2, 0, 2, 0, 1, 0, 2), 'q1'): Win, action: human_place_2_2: 1
Enter state to select from: 0
Choosing state: ((1, 1, 2, 2, 2, 0, 1, 0, 0), 'q1')
R | R | H
H | H | -
R | - | -
human_place_1_0
[0], state:((1, 1, 2, 2, 2, 1, 1, 0, 0), 'q1'): Win, action: robot_place_1_2: 1
[1], state:((1, 1, 2, 2, 2, 0, 1, 1, 0), 'q1'): Win, action: robot_place_2_1: inf
[2], state:((1, 1, 2, 2, 2, 0, 1, 0, 1), 'q1'): Win, action: robot_place_2_2: inf
Sys Strategy: [Wcoop] ((1, 1, 2, 2, 2, 1, 1, 0, 0), 'q1')
Enter state to select from: 0
Choosing state: ((1, 1, 2, 2, 2, 1, 1, 0, 0), 'q1')
R | R | H
H | H | R
R | - | -
robot_place_1_2
[0], state:((1, 1, 2, 2, 2, 1, 1, 2, 0), 'q1'): Win, action: human_place_2_1: 1
[1], state:((1, 1, 2, 2, 2, 1, 1, 0, 2), 'q1'): Win, action: human_place_2_2: 1
Enter state to select from: 0
Choosing state: ((1, 1, 2, 2, 2, 1, 1, 2, 0), 'q1')
R | R | H
H | H | R
R | H | -
human_place_2_1
[0], state:q2: Win, action: robot_place_2_2: 0
Sys Strategy: [Wcoop] q2
Enter state to select from: 0
Choosing state: q2
R | R | H
H | H | R
R | H | -
R | R | H
H | H | R
R | H | -
Action Seq:
robot_place_0_0
human_place_1_1
robot_place_0_1
human_place_0_2
robot_place_2_0
human_place_1_0
robot_place_1_2
human_place_2_1
robot_place_2_2
Function rollout_strategy took 215.21130323410034 seconds to run.
Function run_synthesis_and_rollout took 227.1294722557068 seconds to run.
Function tic_tac_toe_main took 234.04641723632812 seconds to run.
 Peak memory [MB]: 85.56815719604492

**************************Rollout for Video ******************************
R | - | -
- | - | -
- | - | - 


R | - | -
- | H | -
- | - | -


R | R | -
- | H | -
- | - | -



R | R | H
- | H | -
- | - | -


R | R | H
- | H | -
R | - | -


R | R | H
H | H | -
R | - | -

R | R | H
H | H | R
R | - | -

R | R | H
H | H | R
R | H | -


R | R | H
H | H | R
R | H | R

****************************** F(win | draw) **************************************************
****************************** Human -1st **********************************************
Sys ensures the it does make a mistake, i.e., lose the game. But, if the human makes a mistake then Sys will definitely win.


root@668db2aaa591:~/pddltosim# /usr/bin/python3 /root/pddltosim/main.py
pybullet build time: Nov 28 2023 23:45:17
No. of nodes in the Two player game is :5478
No. of edges in the Two player game is :16167
Done building the Product Automaton
No. of nodes in the DFA game is :5479
No. of edges in the DFA game is :17038
Computing Cooperative Winning strategy
/root/pddltosim/regret_synthesis_toolbox/src/strategy_synthesis/value_iteration.py:429: RuntimeWarning: invalid value encountered in cast
  _int_val_vector = self.val_vector[:, -1].astype(int)
******************** Co-op Computation time: 6.888118505477905 ********************
Computing Winning strategy
/root/pddltosim/regret_synthesis_toolbox/src/strategy_synthesis/value_iteration.py:681: RuntimeWarning: invalid value encountered in cast
  _int_val_vector = self.val_vector[:, -1].astype(int)
******************** WCo-op Computation time: 6.626343011856079 ********************
Function compute_strategy took 13.524714231491089 seconds to run.
[0], state:((2, 0, 0, 0, 0, 0, 0, 0, 0), 'q1'): Win, action: human_place_0_0: 4
[1], state:((0, 2, 0, 0, 0, 0, 0, 0, 0), 'q1'): Win, action: human_place_0_1: 4
[2], state:((0, 0, 2, 0, 0, 0, 0, 0, 0), 'q1'): Win, action: human_place_0_2: 4
[3], state:((0, 0, 0, 2, 0, 0, 0, 0, 0), 'q1'): Win, action: human_place_1_0: 4
[4], state:((0, 0, 0, 0, 2, 0, 0, 0, 0), 'q1'): Win, action: human_place_1_1: 4
[5], state:((0, 0, 0, 0, 0, 2, 0, 0, 0), 'q1'): Win, action: human_place_1_2: 4
[6], state:((0, 0, 0, 0, 0, 0, 2, 0, 0), 'q1'): Win, action: human_place_2_0: 4
[7], state:((0, 0, 0, 0, 0, 0, 0, 2, 0), 'q1'): Win, action: human_place_2_1: 4
[8], state:((0, 0, 0, 0, 0, 0, 0, 0, 2), 'q1'): Win, action: human_place_2_2: 4
Enter state to select from: 4
Choosing state: ((0, 0, 0, 0, 2, 0, 0, 0, 0), 'q1')
- | - | -
- | H | -
- | - | -
[0], state:((1, 0, 0, 0, 2, 0, 0, 0, 0), 'q1'): Win, action: robot_place_0_0: 3
[1], state:((0, 1, 0, 0, 2, 0, 0, 0, 0), 'q1'): Win, action: robot_place_0_1: inf
[2], state:((0, 0, 1, 0, 2, 0, 0, 0, 0), 'q1'): Win, action: robot_place_0_2: 3
[3], state:((0, 0, 0, 1, 2, 0, 0, 0, 0), 'q1'): Win, action: robot_place_1_0: inf
[4], state:((0, 0, 0, 0, 2, 1, 0, 0, 0), 'q1'): Win, action: robot_place_1_2: inf
[5], state:((0, 0, 0, 0, 2, 0, 1, 0, 0), 'q1'): Win, action: robot_place_2_0: 3
[6], state:((0, 0, 0, 0, 2, 0, 0, 1, 0), 'q1'): Win, action: robot_place_2_1: inf
[7], state:((0, 0, 0, 0, 2, 0, 0, 0, 1), 'q1'): Win, action: robot_place_2_2: 3
Sys Strategy: [Wcoop] ((1, 0, 0, 0, 2, 0, 0, 0, 0), 'q1')
Sys Strategy: [Wcoop] ((0, 0, 1, 0, 2, 0, 0, 0, 0), 'q1')
Sys Strategy: [Wcoop] ((0, 0, 0, 0, 2, 0, 1, 0, 0), 'q1')
Sys Strategy: [Wcoop] ((0, 0, 0, 0, 2, 0, 0, 0, 1), 'q1')
Enter state to select from: 0
Choosing state: ((1, 0, 0, 0, 2, 0, 0, 0, 0), 'q1')
R | - | -
- | H | -
- | - | -
robot_place_0_0
[0], state:((1, 2, 0, 0, 2, 0, 0, 0, 0), 'q1'): Win, action: human_place_0_1: 3
[1], state:((1, 0, 2, 0, 2, 0, 0, 0, 0), 'q1'): Win, action: human_place_0_2: 3
[2], state:((1, 0, 0, 2, 2, 0, 0, 0, 0), 'q1'): Win, action: human_place_1_0: 3
[3], state:((1, 0, 0, 0, 2, 2, 0, 0, 0), 'q1'): Win, action: human_place_1_2: 3
[4], state:((1, 0, 0, 0, 2, 0, 2, 0, 0), 'q1'): Win, action: human_place_2_0: 3
[5], state:((1, 0, 0, 0, 2, 0, 0, 2, 0), 'q1'): Win, action: human_place_2_1: 3
[6], state:((1, 0, 0, 0, 2, 0, 0, 0, 2), 'q1'): Win, action: human_place_2_2: 3
Enter state to select from: 5
Choosing state: ((1, 0, 0, 0, 2, 0, 0, 2, 0), 'q1')
R | - | -
- | H | -
- | H | -
human_place_2_1
[0], state:((1, 1, 0, 0, 2, 0, 0, 2, 0), 'q1'): Win, action: robot_place_0_1: 2
[1], state:((1, 0, 1, 0, 2, 0, 0, 2, 0), 'q1'): Win, action: robot_place_0_2: inf
[2], state:((1, 0, 0, 1, 2, 0, 0, 2, 0), 'q1'): Win, action: robot_place_1_0: inf
[3], state:((1, 0, 0, 0, 2, 1, 0, 2, 0), 'q1'): Win, action: robot_place_1_2: inf
[4], state:((1, 0, 0, 0, 2, 0, 1, 2, 0), 'q1'): Win, action: robot_place_2_0: inf
[5], state:((1, 0, 0, 0, 2, 0, 0, 2, 1), 'q1'): Win, action: robot_place_2_2: inf
Sys Strategy: [Wcoop] ((1, 1, 0, 0, 2, 0, 0, 2, 0), 'q1')
Enter state to select from: 0
Choosing state: ((1, 1, 0, 0, 2, 0, 0, 2, 0), 'q1')
R | R | -
- | H | -
- | H | -
robot_place_0_1
[0], state:((1, 1, 2, 0, 2, 0, 0, 2, 0), 'q1'): Win, action: human_place_0_2: 2
[1], state:((1, 1, 0, 2, 2, 0, 0, 2, 0), 'q1'): Win, action: human_place_1_0: 1
[2], state:((1, 1, 0, 0, 2, 2, 0, 2, 0), 'q1'): Win, action: human_place_1_2: 1
[3], state:((1, 1, 0, 0, 2, 0, 2, 2, 0), 'q1'): Win, action: human_place_2_0: 1
[4], state:((1, 1, 0, 0, 2, 0, 0, 2, 2), 'q1'): Win, action: human_place_2_2: 1
Enter state to select from: 0
Choosing state: ((1, 1, 2, 0, 2, 0, 0, 2, 0), 'q1')
R | R | H
- | H | -
- | H | -
human_place_0_2
[0], state:((1, 1, 2, 1, 2, 0, 0, 2, 0), 'q1'): Win, action: robot_place_1_0: inf
[1], state:((1, 1, 2, 0, 2, 1, 0, 2, 0), 'q1'): Win, action: robot_place_1_2: inf
[2], state:((1, 1, 2, 0, 2, 0, 1, 2, 0), 'q1'): Win, action: robot_place_2_0: 1
[3], state:((1, 1, 2, 0, 2, 0, 0, 2, 1), 'q1'): Win, action: robot_place_2_2: inf
Sys Strategy: [Wcoop] ((1, 1, 2, 0, 2, 0, 1, 2, 0), 'q1')
Enter state to select from: 2
Choosing state: ((1, 1, 2, 0, 2, 0, 1, 2, 0), 'q1')
R | R | H
- | H | -
R | H | -
robot_place_2_0
[0], state:((1, 1, 2, 2, 2, 0, 1, 2, 0), 'q1'): Win, action: human_place_1_0: 1
[1], state:((1, 1, 2, 0, 2, 2, 1, 2, 0), 'q1'): Win, action: human_place_1_2: 1
[2], state:((1, 1, 2, 0, 2, 0, 1, 2, 2), 'q1'): Win, action: human_place_2_2: 1
Enter state to select from: 0
Choosing state: ((1, 1, 2, 2, 2, 0, 1, 2, 0), 'q1')
R | R | H
H | H | -
R | H | -
human_place_1_0
[0], state:((1, 1, 2, 2, 2, 1, 1, 2, 0), 'q1'): Win, action: robot_place_1_2: 0
[1], state:((1, 1, 2, 2, 2, 0, 1, 2, 1), 'q1'): Win, action: robot_place_2_2: inf
Sys Strategy: [Wcoop] ((1, 1, 2, 2, 2, 1, 1, 2, 0), 'q1')
Enter state to select from: 0
Choosing state: ((1, 1, 2, 2, 2, 1, 1, 2, 0), 'q1')
R | R | H
H | H | R
R | H | -
robot_place_1_2
[0], state:q2: Win, action: human_place_2_2: 0
Enter state to select from: 0
Choosing state: q2
R | R | H
H | H | R
R | H | -
R | R | H
H | H | R
R | H | -
Action Seq:
human_place_1_1
robot_place_0_0
human_place_2_1
robot_place_0_1
human_place_0_2
robot_place_2_0
human_place_1_0
robot_place_1_2
human_place_2_2
Function rollout_strategy took 105.13571882247925 seconds to run.
Function run_synthesis_and_rollout took 117.22111105918884 seconds to run.
Function tic_tac_toe_main took 124.0906445980072 seconds to run.
Peak memory [MB]: 90.43976783752441

**************************Rollout for Video ******************************

- | - | -
- | H | -
- | - | -


R | - | -
- | H | -
- | - | -


R | - | -
- | H | -
- | H | -


R | R | -
- | H | -
- | H | -


R | R | H
- | H | -
R | H | -


R | R | H
- | H | -
R | H | -